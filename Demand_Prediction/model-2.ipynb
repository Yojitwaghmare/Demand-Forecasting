{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Model  2 dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert Order_Date to datetime\n",
    "df['Order_Date'] = pd.to_datetime(df['Order_Date'])\n",
    "\n",
    "# Sort the data by product and date\n",
    "df.sort_values(by=['Product_ID', 'Order_Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2021-03-20\n",
      "1   2020-09-28\n",
      "2   2023-02-06\n",
      "3   2022-04-18\n",
      "4   2022-11-22\n",
      "Name: Order_Date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(df['Order_Date'].head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "label_encoder = LabelEncoder()\n",
    "df['Product_ID'] = label_encoder.fit_transform(df['Product_ID'])\n",
    "df['Category'] = label_encoder.fit_transform(df['Category'])\n",
    "df['Sales_Channel'] = label_encoder.fit_transform(df['Sales_Channel'])\n",
    "df['Customer_Segment'] = label_encoder.fit_transform(df['Customer_Segment'])\n",
    "df['Seasonality'] = label_encoder.fit_transform(df['Seasonality'])\n",
    "df['Holiday_Indicator'] = label_encoder.fit_transform(df['Holiday_Indicator'])\n",
    "df['Weather_Conditions'] = label_encoder.fit_transform(df['Weather_Conditions'])\n",
    "df['Return_Reason'] = label_encoder.fit_transform(df['Return_Reason'])\n",
    "df['Region'] = label_encoder.fit_transform(df['Region'])\n",
    "df['Warehouse_Location'] = label_encoder.fit_transform(df['Warehouse_Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Price', 'Cost','Sales_Channel', 'Customer_Segment', \n",
    "            'Stock_Level', 'Safety_Stock_Level', 'Reorder_Point', 'Lead_Time', 'Supplier_Reliability', \n",
    "            'Seasonality', 'Holiday_Indicator', 'Economic_Indicators', 'Weather_Conditions', \n",
    "            'Promotion_Flag', 'Discount_Rate', 'Marketing_Spend', 'Competitor_Price', \n",
    "            'Competitor_Promotion', 'Return_Quantity', 'Average_Order_Interval', 'Region', 'Warehouse_Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Order_Date_Ordinal'] = df['Order_Date'].map(lambda x: x.toordinal())\n",
    "features.append('Order_Date_Ordinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Order_Quantity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(df[features])\n",
    "y = df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into time series format\n",
    "def create_dataset(X, y, time_step=1):\n",
    "    X_data, y_data = [], []\n",
    "    for i in range(len(X) - time_step):\n",
    "        X_data.append(X[i:(i + time_step)])\n",
    "        y_data.append(y[i + time_step])\n",
    "    return np.array(X_data), np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time_step for LSTM\n",
    "time_step = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LSTM\n",
    "X_lstm, y_lstm = create_dataset(X_scaled, y, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lstm, y_lstm, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yojee\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    LSTM(32, return_sequences=False),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 657.6575 - val_loss: 420.4468\n",
      "Epoch 2/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 411.1716 - val_loss: 324.7046\n",
      "Epoch 3/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 319.5211 - val_loss: 267.1159\n",
      "Epoch 4/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 265.2523 - val_loss: 234.0441\n",
      "Epoch 5/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 234.1734 - val_loss: 216.3078\n",
      "Epoch 6/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 217.6821 - val_loss: 207.8256\n",
      "Epoch 7/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 213.5384 - val_loss: 204.2733\n",
      "Epoch 8/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 209.9483 - val_loss: 202.9695\n",
      "Epoch 9/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 209.4712 - val_loss: 202.5480\n",
      "Epoch 10/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 210.7075 - val_loss: 202.4424\n",
      "Epoch 11/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 208.5256 - val_loss: 202.4373\n",
      "Epoch 12/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 207.7968 - val_loss: 202.4545\n",
      "Epoch 13/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 210.1945 - val_loss: 202.4602\n",
      "Epoch 14/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 206.5362 - val_loss: 202.4554\n",
      "Epoch 15/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 207.6841 - val_loss: 202.4550\n",
      "Epoch 16/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 209.6939 - val_loss: 202.4674\n",
      "Epoch 17/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 212.2267 - val_loss: 202.4481\n",
      "Epoch 18/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 212.5561 - val_loss: 202.4710\n",
      "Epoch 19/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 213.2216 - val_loss: 202.4662\n",
      "Epoch 20/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 211.6718 - val_loss: 202.4601\n",
      "Epoch 21/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 208.0826 - val_loss: 202.4576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x164a7b09520>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_order_quantity(order_date, product_id):\n",
    "    \"\"\"\n",
    "    Predict the order quantity based on the given order date and product ID using the trained model.\n",
    "    \n",
    "    Parameters:\n",
    "    - order_date (str): The order date in 'YYYY-MM-DD' format.\n",
    "    - product_id (int): The product ID (integer).\n",
    "    \n",
    "    Returns:\n",
    "    - float: The predicted order quantity.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert Order_Date to ordinal format\n",
    "    input_date = pd.to_datetime(order_date)\n",
    "    input_date_ordinal = input_date.toordinal()\n",
    "    \n",
    "    # Fill in other feature values with historical averages or defaults\n",
    "    default_features = {\n",
    "        'Price': 100,                # Example average price\n",
    "        'Cost': 50,                  # Example average cost\n",
    "        'Sales_Channel': 1,          # Default encoded value\n",
    "        'Customer_Segment': 1,\n",
    "        'Stock_Level': 500,\n",
    "        'Safety_Stock_Level': 50,\n",
    "        'Reorder_Point': 100,\n",
    "        'Lead_Time': 5,\n",
    "        'Supplier_Reliability': 0.95,\n",
    "        'Seasonality': 1,\n",
    "        'Holiday_Indicator': 0,\n",
    "        'Economic_Indicators': 1.0,\n",
    "        'Weather_Conditions': 1,\n",
    "        'Promotion_Flag': 0,\n",
    "        'Discount_Rate': 0.1,\n",
    "        'Marketing_Spend': 200,\n",
    "        'Competitor_Price': 110,\n",
    "        'Competitor_Promotion': 0,\n",
    "        'Return_Quantity': 10,\n",
    "        'Average_Order_Interval': 30,\n",
    "        'Region': 1,\n",
    "        'Warehouse_Location': 1,\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # Build input features (including Product_ID)\n",
    "    input_features = default_features\n",
    "    input_features['Product_ID'] = product_id  # Product ID should be included\n",
    "    \n",
    "    # Convert input features to array\n",
    "    input_array = list(input_features.values())\n",
    "    \n",
    "    # Check if the number of features is correct\n",
    "    # if len(input_array) != 24:\n",
    "    #     print(f\"Error: Expected 24 features, but found {len(input_array)}.\")\n",
    "    #     return None\n",
    "    \n",
    "    # Normalize the input features using the previously fitted scaler\n",
    "    input_array_scaled = scaler.transform([input_array])  # Scaling with 24 features\n",
    "    \n",
    "    # Format input for LSTM (time-step, features)\n",
    "    input_lstm = np.expand_dims(input_array_scaled, axis=0)  # Shape: (1, time_step, features)\n",
    "    \n",
    "    # Predict order quantity\n",
    "    predicted_quantity = model.predict(input_lstm)\n",
    "    return predicted_quantity[0][0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Predicted Order Quantity: 43.68339920043945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yojee\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predicted_quantity = predict_order_quantity(\n",
    "    order_date='2024-02-14',\n",
    "    product_id=1005 \n",
    ")\n",
    "\n",
    "print(f'Predicted Order Quantity: {predicted_quantity}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
