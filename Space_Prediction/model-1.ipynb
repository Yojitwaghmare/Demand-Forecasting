{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961e0cce-60a6-4dea-b64d-d1f32a46eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88ce122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Model 1 dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "095f5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'current_space_utilization', 'historical_space_utilization',\n",
    "    'average_weekly_space_utilization', 'total_inventory_items',\n",
    "    'incoming_shipments', 'outgoing_shipments', 'inventory_turnover_rate',\n",
    "    'product_categories', 'bulk_items_count', 'perishable_items_count',\n",
    "    'seasonal_products_count', 'staff_count', 'operational_hours',\n",
    "    'equipment_usage', 'market_trends', 'promotional_events',\n",
    "    'supplier_delays', 'economic_indicators', 'special_events',\n",
    "    'anomalies', 'rental_cost_per_sq_ft', 'space_savings',\n",
    "    'transportation_lead_time', 'delivery_frequency',\n",
    "    'historical_demand'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf54fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'forecasted_demand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8746238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X = df[features].values\n",
    "y = df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47571fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a5fef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "X_scaled = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1becf733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f62d10b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yojee\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bd84dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e9e9559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bafdab7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 2347748096.0000 - mae: 48113.4258 - val_loss: 2355600128.0000 - val_mae: 48183.9648\n",
      "Epoch 2/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2353981696.0000 - mae: 48175.9258 - val_loss: 2346986240.0000 - val_mae: 48094.4883\n",
      "Epoch 3/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2332351488.0000 - mae: 47945.1406 - val_loss: 2336631808.0000 - val_mae: 47986.7266\n",
      "Epoch 4/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2319678720.0000 - mae: 47820.7930 - val_loss: 2323725824.0000 - val_mae: 47852.0586\n",
      "Epoch 5/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2310683136.0000 - mae: 47719.6719 - val_loss: 2308165632.0000 - val_mae: 47689.1914\n",
      "Epoch 6/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2282878208.0000 - mae: 47411.8320 - val_loss: 2290006016.0000 - val_mae: 47498.4180\n",
      "Epoch 7/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2239154944.0000 - mae: 46964.4961 - val_loss: 2269278208.0000 - val_mae: 47279.7266\n",
      "Epoch 8/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2257461760.0000 - mae: 47169.1797 - val_loss: 2246072064.0000 - val_mae: 47033.6641\n",
      "Epoch 9/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2215649792.0000 - mae: 46715.0859 - val_loss: 2220502272.0000 - val_mae: 46761.0430\n",
      "Epoch 10/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2203894272.0000 - mae: 46585.6484 - val_loss: 2192609280.0000 - val_mae: 46461.8516\n",
      "Epoch 11/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2172674048.0000 - mae: 46256.1602 - val_loss: 2162689536.0000 - val_mae: 46138.7344\n",
      "Epoch 12/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2148904704.0000 - mae: 45987.9219 - val_loss: 2130718976.0000 - val_mae: 45790.9648\n",
      "Epoch 13/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2100851840.0000 - mae: 45467.1250 - val_loss: 2096862208.0000 - val_mae: 45419.7734\n",
      "Epoch 14/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2063306112.0000 - mae: 45043.4844 - val_loss: 2061156352.0000 - val_mae: 45024.9922\n",
      "Epoch 15/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2031566976.0000 - mae: 44694.9219 - val_loss: 2023860864.0000 - val_mae: 44608.9062\n",
      "Epoch 16/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2002489984.0000 - mae: 44380.9180 - val_loss: 1984979712.0000 - val_mae: 44170.9531\n",
      "Epoch 17/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1947160576.0000 - mae: 43749.9062 - val_loss: 1944777984.0000 - val_mae: 43713.5078\n",
      "Epoch 18/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1929593600.0000 - mae: 43547.3594 - val_loss: 1903217920.0000 - val_mae: 43235.5352\n",
      "Epoch 19/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1880117632.0000 - mae: 42972.1602 - val_loss: 1860616448.0000 - val_mae: 42740.0312\n",
      "Epoch 20/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1845621632.0000 - mae: 42566.6992 - val_loss: 1816977152.0000 - val_mae: 42226.4180\n",
      "Epoch 21/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1795411200.0000 - mae: 41975.0508 - val_loss: 1772509184.0000 - val_mae: 41696.5547\n",
      "Epoch 22/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1751644928.0000 - mae: 41444.3906 - val_loss: 1727143936.0000 - val_mae: 41148.9688\n",
      "Epoch 23/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1714256896.0000 - mae: 40991.4609 - val_loss: 1681066240.0000 - val_mae: 40585.2148\n",
      "Epoch 24/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1661750528.0000 - mae: 40343.3477 - val_loss: 1634551424.0000 - val_mae: 40008.0625\n",
      "Epoch 25/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1604126848.0000 - mae: 39620.5820 - val_loss: 1587507968.0000 - val_mae: 39415.7500\n",
      "Epoch 26/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1565730432.0000 - mae: 39126.6875 - val_loss: 1540042496.0000 - val_mae: 38808.9688\n",
      "Epoch 27/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1513336704.0000 - mae: 38457.3242 - val_loss: 1492288896.0000 - val_mae: 38188.7695\n",
      "Epoch 28/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1466980096.0000 - mae: 37871.0781 - val_loss: 1444276864.0000 - val_mae: 37554.8984\n",
      "Epoch 29/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1413067776.0000 - mae: 37126.8711 - val_loss: 1396320128.0000 - val_mae: 36910.8867\n",
      "Epoch 30/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1379021056.0000 - mae: 36680.5352 - val_loss: 1348250624.0000 - val_mae: 36253.8828\n",
      "Epoch 31/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1320651136.0000 - mae: 35864.1914 - val_loss: 1300364672.0000 - val_mae: 35587.3281\n",
      "Epoch 32/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1283052928.0000 - mae: 35335.5000 - val_loss: 1252584192.0000 - val_mae: 34909.5664\n",
      "Epoch 33/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1217329792.0000 - mae: 34413.2305 - val_loss: 1205179776.0000 - val_mae: 34223.8711\n",
      "Epoch 34/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1188088320.0000 - mae: 33963.1289 - val_loss: 1158012032.0000 - val_mae: 33527.6836\n",
      "Epoch 35/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1146829952.0000 - mae: 33342.0273 - val_loss: 1111222656.0000 - val_mae: 32822.4922\n",
      "Epoch 36/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1091420928.0000 - mae: 32504.7871 - val_loss: 1065026176.0000 - val_mae: 32111.0566\n",
      "Epoch 37/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1037431040.0000 - mae: 31660.4043 - val_loss: 1019235520.0000 - val_mae: 31389.9492\n",
      "Epoch 38/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1000993536.0000 - mae: 31088.9512 - val_loss: 974186880.0000 - val_mae: 30663.9902\n",
      "Epoch 39/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 956436992.0000 - mae: 30366.7422 - val_loss: 929779392.0000 - val_mae: 29931.1348\n",
      "Epoch 40/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 915448512.0000 - mae: 29664.4727 - val_loss: 886159744.0000 - val_mae: 29193.3789\n",
      "Epoch 41/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 860641856.0000 - mae: 28736.3809 - val_loss: 843373440.0000 - val_mae: 28451.1309\n",
      "Epoch 42/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 830300608.0000 - mae: 28182.4668 - val_loss: 801341440.0000 - val_mae: 27702.6152\n",
      "Epoch 43/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 775727616.0000 - mae: 27234.3809 - val_loss: 760237952.0000 - val_mae: 26950.5352\n",
      "Epoch 44/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 748886912.0000 - mae: 26689.4883 - val_loss: 720135808.0000 - val_mae: 26195.9785\n",
      "Epoch 45/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 711092288.0000 - mae: 25987.1758 - val_loss: 680897088.0000 - val_mae: 25436.0098\n",
      "Epoch 46/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 659045952.0000 - mae: 24985.4609 - val_loss: 642898752.0000 - val_mae: 24677.7676\n",
      "Epoch 47/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 633849216.0000 - mae: 24422.4238 - val_loss: 605953152.0000 - val_mae: 23917.4941\n",
      "Epoch 48/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 589338624.0000 - mae: 23518.1934 - val_loss: 570048704.0000 - val_mae: 23154.7402\n",
      "Epoch 49/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 554652672.0000 - mae: 22766.6543 - val_loss: 535309504.0000 - val_mae: 22392.0273\n",
      "Epoch 50/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 519914528.0000 - mae: 22006.9863 - val_loss: 501814688.0000 - val_mae: 21631.1816\n",
      "Epoch 51/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 494791776.0000 - mae: 21389.9629 - val_loss: 469430432.0000 - val_mae: 20869.2070\n",
      "Epoch 52/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 448581056.0000 - mae: 20304.8086 - val_loss: 438466976.0000 - val_mae: 20113.6875\n",
      "Epoch 53/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 428401152.0000 - mae: 19784.1250 - val_loss: 408629984.0000 - val_mae: 19357.7715\n",
      "Epoch 54/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 407154624.0000 - mae: 19191.3086 - val_loss: 380003264.0000 - val_mae: 18603.6738\n",
      "Epoch 55/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 359261696.0000 - mae: 17958.3027 - val_loss: 352793280.0000 - val_mae: 17857.3965\n",
      "Epoch 56/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 345869312.0000 - mae: 17581.1992 - val_loss: 326830784.0000 - val_mae: 17115.0293\n",
      "Epoch 57/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 319776992.0000 - mae: 16767.6113 - val_loss: 302242176.0000 - val_mae: 16380.9502\n",
      "Epoch 58/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 299194272.0000 - mae: 16153.0068 - val_loss: 278809760.0000 - val_mae: 15649.3848\n",
      "Epoch 59/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 282873856.0000 - mae: 15608.5508 - val_loss: 256756576.0000 - val_mae: 14928.1611\n",
      "Epoch 60/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 250259808.0000 - mae: 14509.6777 - val_loss: 235954944.0000 - val_mae: 14214.3721\n",
      "Epoch 61/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 230636192.0000 - mae: 13852.2041 - val_loss: 216452640.0000 - val_mae: 13510.9609\n",
      "Epoch 62/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 217023504.0000 - mae: 13367.2510 - val_loss: 198149168.0000 - val_mae: 12815.7168\n",
      "Epoch 63/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 194092384.0000 - mae: 12408.5088 - val_loss: 181179680.0000 - val_mae: 12135.6123\n",
      "Epoch 64/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 174649744.0000 - mae: 11681.0020 - val_loss: 165399696.0000 - val_mae: 11467.0449\n",
      "Epoch 65/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163776720.0000 - mae: 11223.4785 - val_loss: 150778448.0000 - val_mae: 10810.7305\n",
      "Epoch 66/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153336624.0000 - mae: 10715.3984 - val_loss: 137281216.0000 - val_mae: 10167.4648\n",
      "Epoch 67/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140312800.0000 - mae: 10171.7793 - val_loss: 124954840.0000 - val_mae: 9565.5312\n",
      "Epoch 68/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 124117584.0000 - mae: 9416.4150 - val_loss: 113775080.0000 - val_mae: 9017.2422\n",
      "Epoch 69/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113770816.0000 - mae: 8949.7666 - val_loss: 103557936.0000 - val_mae: 8517.8184\n",
      "Epoch 70/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 106970296.0000 - mae: 8674.4170 - val_loss: 94231480.0000 - val_mae: 8054.4248\n",
      "Epoch 71/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 97570944.0000 - mae: 8158.1582 - val_loss: 85840496.0000 - val_mae: 7636.3452\n",
      "Epoch 72/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 89493464.0000 - mae: 7807.4126 - val_loss: 78413192.0000 - val_mae: 7273.6274\n",
      "Epoch 73/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 85807600.0000 - mae: 7563.2349 - val_loss: 71890352.0000 - val_mae: 6953.6787\n",
      "Epoch 74/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 71635272.0000 - mae: 6869.1880 - val_loss: 66138272.0000 - val_mae: 6674.7783\n",
      "Epoch 75/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 70629400.0000 - mae: 6854.2275 - val_loss: 60974648.0000 - val_mae: 6424.4482\n",
      "Epoch 76/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 69145312.0000 - mae: 6774.0811 - val_loss: 56556920.0000 - val_mae: 6203.4731\n",
      "Epoch 77/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60986116.0000 - mae: 6373.5215 - val_loss: 52687148.0000 - val_mae: 6006.5601\n",
      "Epoch 78/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 64651036.0000 - mae: 6603.8584 - val_loss: 49383116.0000 - val_mae: 5843.8672\n",
      "Epoch 79/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56189576.0000 - mae: 6146.6543 - val_loss: 46717132.0000 - val_mae: 5715.1445\n",
      "Epoch 80/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54163172.0000 - mae: 6081.1875 - val_loss: 44350808.0000 - val_mae: 5602.2266\n",
      "Epoch 81/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 53930504.0000 - mae: 6061.2974 - val_loss: 42343640.0000 - val_mae: 5505.2856\n",
      "Epoch 82/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50494112.0000 - mae: 5806.6753 - val_loss: 40706664.0000 - val_mae: 5425.1187\n",
      "Epoch 83/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48688076.0000 - mae: 5757.4790 - val_loss: 39385540.0000 - val_mae: 5357.0381\n",
      "Epoch 84/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 49063044.0000 - mae: 5788.0547 - val_loss: 38306816.0000 - val_mae: 5303.0938\n",
      "Epoch 85/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45877936.0000 - mae: 5544.9985 - val_loss: 37353704.0000 - val_mae: 5257.1855\n",
      "Epoch 86/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43327728.0000 - mae: 5463.8901 - val_loss: 36639124.0000 - val_mae: 5223.7788\n",
      "Epoch 87/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45772144.0000 - mae: 5631.4253 - val_loss: 36084412.0000 - val_mae: 5197.8457\n",
      "Epoch 88/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44578676.0000 - mae: 5557.1016 - val_loss: 35615064.0000 - val_mae: 5175.9785\n",
      "Epoch 89/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44537444.0000 - mae: 5500.8232 - val_loss: 35239688.0000 - val_mae: 5158.0718\n",
      "Epoch 90/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44443028.0000 - mae: 5534.3130 - val_loss: 34962168.0000 - val_mae: 5144.5142\n",
      "Epoch 91/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44899692.0000 - mae: 5587.9341 - val_loss: 34729200.0000 - val_mae: 5132.7510\n",
      "Epoch 92/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 46214772.0000 - mae: 5704.4717 - val_loss: 34543272.0000 - val_mae: 5123.3506\n",
      "Epoch 93/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44700832.0000 - mae: 5620.7124 - val_loss: 34406704.0000 - val_mae: 5115.9570\n",
      "Epoch 94/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43874012.0000 - mae: 5511.9829 - val_loss: 34333284.0000 - val_mae: 5111.8809\n",
      "Epoch 95/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45817840.0000 - mae: 5667.5518 - val_loss: 34273424.0000 - val_mae: 5108.5068\n",
      "Epoch 96/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44124476.0000 - mae: 5542.3193 - val_loss: 34241196.0000 - val_mae: 5106.7222\n",
      "Epoch 97/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43584456.0000 - mae: 5478.5068 - val_loss: 34209780.0000 - val_mae: 5104.9585\n",
      "Epoch 98/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43834668.0000 - mae: 5525.2280 - val_loss: 34154976.0000 - val_mae: 5101.8564\n",
      "Epoch 99/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48651772.0000 - mae: 5872.6328 - val_loss: 34138960.0000 - val_mae: 5100.9385\n",
      "Epoch 100/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41930480.0000 - mae: 5403.3501 - val_loss: 34116156.0000 - val_mae: 5099.6494\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2,\n",
    "                    callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e290b50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32571816.0000 - mae: 4939.2827\n",
      "Test Loss: 33104166.0, Test MAE: 4977.0478515625\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test MAE: {test_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33d90f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Model Accuracy: 89.41%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = 1 - (np.abs(predictions.flatten() - y_test) / y_test).mean()\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
